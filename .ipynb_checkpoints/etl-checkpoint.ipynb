{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2355a548",
   "metadata": {},
   "source": [
    "# ETL (Extract, Transform and Load)\n",
    "## Trabalho Final | Prática | Grupo G\n",
    "Base de dados usada: https://www.kaggle.com/datasets/whenamancodes/popular-movies-datasets-58000-movies?select=tags.csv'\n",
    "\n",
    "Slide: [Canva](https://www.canva.com/design/DAFYb14LbAA/J_Kk7ndEoZM1m3Tw_glTIA/edit?utm_content=DAFYb14LbAA&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton)\n",
    "\n",
    "|Alunos|Matrícula|\n",
    "|--|--|\n",
    "|Victor Buendia Cruz De Alvim|19/0020601|\n",
    "|Lucas Ursulino Boaventura|18/0114093|\n",
    "|Yudi Yamane de Azevedo|16/0149410|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ced05a",
   "metadata": {},
   "source": [
    "##  ⚙️ Setup ==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e7fb837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opendatasets pandas pandasql findspark pyspark --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "061ed227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandasql import sqldf\n",
    "import opendatasets as od\n",
    "import pandas\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b777f23",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local) created by __init__ at /var/folders/9k/d6j_tzp50jdg1b8j8_54hkr80000gn/T/ipykernel_69673/2899417565.py:5 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkContext\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msession\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m----> 5\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession(sc)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pyspark/context.py:195\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m     )\n\u001b[0;32m--> 195\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[1;32m    198\u001b[0m         master,\n\u001b[1;32m    199\u001b[0m         appName,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m         udf_profiler_cls,\n\u001b[1;32m    209\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pyspark/context.py:430\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    427\u001b[0m     callsite \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\u001b[38;5;241m.\u001b[39m_callsite\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;66;03m# Raise error if there is already a running Spark context\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot run multiple SparkContexts at once; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexisting SparkContext(app=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, master=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    433\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m created by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    435\u001b[0m             currentAppName,\n\u001b[1;32m    436\u001b[0m             currentMaster,\n\u001b[1;32m    437\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mfunction,\n\u001b[1;32m    438\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mfile,\n\u001b[1;32m    439\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mlinenum,\n\u001b[1;32m    440\u001b[0m         )\n\u001b[1;32m    441\u001b[0m     )\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    443\u001b[0m     SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;241m=\u001b[39m instance\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local) created by __init__ at /var/folders/9k/d6j_tzp50jdg1b8j8_54hkr80000gn/T/ipykernel_69673/2899417565.py:5 "
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext('local')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81b474c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe93a4aa",
   "metadata": {},
   "source": [
    "## ⬇️ Extract ============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7df215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./popular-movies-datasets-58000-movies/'):\n",
    "    kaggleAPI = input('[TOKEN API] Insire seu Token API do Kaggle:')\n",
    "\n",
    "    fp = open('kaggle.json', 'w')\n",
    "    fp.write(kaggleAPI)\n",
    "    fp.close()\n",
    "\n",
    "    od.download(\n",
    "        'https://www.kaggle.com/datasets/whenamancodes/popular-movies-datasets-58000-movies?select=tags.csv')\n",
    "\n",
    "    os.remove('kaggle.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a9ec7ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./popular-movies-datasets-58000-movies/links.csv\n",
      "./popular-movies-datasets-58000-movies/tags.csv\n",
      "./popular-movies-datasets-58000-movies/genome-tags.csv\n",
      "./popular-movies-datasets-58000-movies/ratings.csv\n",
      "./popular-movies-datasets-58000-movies/genome-scores.csv\n",
      "./popular-movies-datasets-58000-movies/movies.csv\n"
     ]
    }
   ],
   "source": [
    "csvs = {}\n",
    "for dirname, _, filenames in os.walk('./popular-movies-datasets-58000-movies/'):\n",
    "    for filename in filenames:\n",
    "        csvs[filename] = os.path.join(dirname, filename)\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98ea39e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "\n",
    "for filename in csvs:\n",
    "    file=(csvs[filename])\n",
    "    newData = spark.read.format(\"csv\").option(\"header\",\"true\").load(file)\n",
    "    dfs[re.sub('-', '_', re.findall(\"(.+).csv\", filename)[0])] = newData\n",
    "    newData.createOrReplaceTempView(re.sub('-', '_', re.findall(\"(.+).csv\", filename)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd625b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    print(df,'\\n |-->', dfs[df], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69504e1",
   "metadata": {},
   "source": [
    "# ✨ Transform ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b4f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqlR(sql):\n",
    "    return (spark.sql(sql).toPandas())\n",
    "\n",
    "def tView(sql, name):\n",
    "    spark.sql(sql).createOrReplaceTempView(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82515ea5",
   "metadata": {},
   "source": [
    "---\n",
    "## Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "185aff14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>publish_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>[Adventure, Children, Fantasy]</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>[Comedy, Drama, Romance]</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58093</th>\n",
       "      <td>193876</td>\n",
       "      <td>The Great Glinka</td>\n",
       "      <td>[(no genres listed)]</td>\n",
       "      <td>1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58094</th>\n",
       "      <td>193878</td>\n",
       "      <td>Les tribulations d'une caissière</td>\n",
       "      <td>[Comedy]</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58095</th>\n",
       "      <td>193880</td>\n",
       "      <td>Her Name Was Mumu</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58096</th>\n",
       "      <td>193882</td>\n",
       "      <td>Flora</td>\n",
       "      <td>[Adventure, Drama, Horror, Sci-Fi]</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58097</th>\n",
       "      <td>193886</td>\n",
       "      <td>Leal</td>\n",
       "      <td>[Action, Crime, Drama]</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58098 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                             title  \\\n",
       "0           1                         Toy Story   \n",
       "1           2                           Jumanji   \n",
       "2           3                  Grumpier Old Men   \n",
       "3           4                 Waiting to Exhale   \n",
       "4           5       Father of the Bride Part II   \n",
       "...       ...                               ...   \n",
       "58093  193876                  The Great Glinka   \n",
       "58094  193878  Les tribulations d'une caissière   \n",
       "58095  193880                 Her Name Was Mumu   \n",
       "58096  193882                             Flora   \n",
       "58097  193886                              Leal   \n",
       "\n",
       "                                                  genres publish_year  \n",
       "0      [Adventure, Animation, Children, Comedy, Fantasy]         1995  \n",
       "1                         [Adventure, Children, Fantasy]         1995  \n",
       "2                                      [Comedy, Romance]         1995  \n",
       "3                               [Comedy, Drama, Romance]         1995  \n",
       "4                                               [Comedy]         1995  \n",
       "...                                                  ...          ...  \n",
       "58093                               [(no genres listed)]         1946  \n",
       "58094                                           [Comedy]         2011  \n",
       "58095                                            [Drama]         2016  \n",
       "58096                 [Adventure, Drama, Horror, Sci-Fi]         2017  \n",
       "58097                             [Action, Crime, Drama]         2018  \n",
       "\n",
       "[58098 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.table('movies')\\\n",
    ".withColumn('genres', F.split(spark.table('movies')['genres'], '\\|'))\\\n",
    ".withColumn('publish_year', F.when(F.regexp_extract(F.col('title'), '\\((\\d\\d\\d\\d)\\)', 1) == '', None)\\\n",
    "                             .otherwise(F.regexp_extract(F.col('title'), '\\((\\d\\d\\d\\d)\\)', 1)))\\\n",
    ".withColumn('title', F.when(F.trim(F.regexp_extract(F.col('title'), '(.+)\\(\\d\\d\\d\\d\\)$', 1))\\\n",
    "                           == '', F.col('title'))\\\n",
    "                           .otherwise(F.trim(F.regexp_extract(F.col('title'), '(.+)\\(\\d\\d\\d\\d\\)$', 1))))\\\n",
    ".createOrReplaceTempView('movies')\n",
    "\n",
    "sql = \"\"\"\n",
    "    SELECT * FROM movies\n",
    "\"\"\"\n",
    "\n",
    "sqlR(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "\n",
    "WITH M AS (\n",
    "    SELECT\n",
    "        M.movieId\n",
    "        , M.title\n",
    "        , M.genres\n",
    "        , M.publish_year\n",
    "        , SUM(R.rating)/COUNT(R.rating) AS average_rating\n",
    "        , COUNT(DISTINCT R.userId) AS user_review_amount\n",
    "        , COUNT(R.rating) AS review_amount\n",
    "    FROM\n",
    "        movies AS M\n",
    "    LEFT JOIN\n",
    "        ratings AS R\n",
    "        ON TRUE\n",
    "            AND M.movieId = R.movieId\n",
    "    GROUP BY\n",
    "        1,2,3,4\n",
    ")\n",
    "\n",
    "SELECT * FROM M\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tView(sql, 'movie_reviews')\n",
    "sqlR(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833e4b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "\n",
    "WITH M AS (\n",
    "    SELECT\n",
    "        M.movieId\n",
    "        , M.title\n",
    "        , M.genres\n",
    "        , M.publish_year\n",
    "        , COUNT(DISTINCT T.userId) AS user_tag_amount\n",
    "        , COUNT(T.tag) AS tag_amount\n",
    "        , ARRAY_AGG(DISTINCT T.tag) AS tags\n",
    "    FROM\n",
    "        movies AS M\n",
    "    LEFT JOIN\n",
    "        tags AS T\n",
    "        ON TRUE\n",
    "            AND T.movieId = M.movieId\n",
    "    GROUP BY\n",
    "        1,2,3,4\n",
    ")\n",
    "\n",
    "SELECT * FROM M\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "tView(sql, 'movie_tags')\n",
    "sqlR(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "\n",
    "SELECT\n",
    "    M.movieId\n",
    "    , M.title\n",
    "    , M.genres\n",
    "    , M.publish_year\n",
    "    , MT.user_tag_amount\n",
    "    , MT.tag_amount\n",
    "    , MT.tags\n",
    "    , MR.average_rating\n",
    "    , MR.user_review_amount\n",
    "    , MR.review_amount\n",
    "FROM\n",
    "    movies AS M\n",
    "LEFT JOIN\n",
    "    movie_reviews AS MR\n",
    "    ON TRUE\n",
    "        AND M.movieId = MR.movieId\n",
    "LEFT JOIN\n",
    "    movie_tags AS MT\n",
    "    ON TRUE\n",
    "        AND M.movieId = MT.movieId\n",
    "ORDER BY\n",
    "    M.title\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "tView(sql, 'movies_df')\n",
    "sqlR(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6fe5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "\n",
    "SELECT\n",
    "    M.movieId\n",
    "    , L.imdbId\n",
    "    , L.tmdbId\n",
    "    , M.title\n",
    "    , M.genres\n",
    "    , M.publish_year\n",
    "    , M.user_tag_amount\n",
    "    , M.tag_amount\n",
    "    , M.tags\n",
    "    , M.average_rating\n",
    "    , M.user_review_amount\n",
    "    , M.review_amount\n",
    "FROM\n",
    "    movies_df AS M\n",
    "LEFT JOIN\n",
    "    links AS L\n",
    "    ON TRUE\n",
    "        AND M.movieId = L.movieId\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "tView(sql, 'movies')\n",
    "sqlR(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a6b57c",
   "metadata": {},
   "source": [
    "---\n",
    "## Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4792e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.table('ratings')\\\n",
    ".withColumn('dt', F.to_date(F.col('timestamp')\\\n",
    "                            .cast('bigint')\\\n",
    "                            .cast(dataType=T.TimestampType()), 'yyyy-MM-dd HH:mm:ss') )\\\n",
    ".withColumn('timestamp', F.col('timestamp')\\\n",
    "                            .cast('bigint')\\\n",
    "                            .cast(dataType=T.TimestampType()) )\\\n",
    ".createOrReplaceTempView('ratings')\n",
    "\n",
    "sql = \"\"\"\n",
    "\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    ratings\n",
    "LIMIT 50\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "tView(sql, 'ratings')\n",
    "sqlR(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeadbd18",
   "metadata": {},
   "source": [
    "---\n",
    "## Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ada45",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.table('tags')\\\n",
    ".withColumn('dt', F.to_date(F.col('timestamp')\\\n",
    "                            .cast('bigint')\\\n",
    "                            .cast(dataType=T.TimestampType()), 'yyyy-MM-dd HH:mm:ss') )\\\n",
    ".withColumn('timestamp', F.col('timestamp')\\\n",
    "                            .cast('bigint')\\\n",
    "                            .cast(dataType=T.TimestampType()) )\\\n",
    ".createOrReplaceTempView('tags')\n",
    "\n",
    "sql = \"\"\"\n",
    "\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    tags\n",
    "LIMIT 50\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "tView(sql, 'ratings')\n",
    "sqlR(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886bf04e",
   "metadata": {},
   "source": [
    "---\n",
    "## Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c6bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "\n",
    "WITH E AS (\n",
    "    SELECT\n",
    "        movieId\n",
    "        , publish_year\n",
    "        , EXPLODE(genres) AS genre\n",
    "    FROM\n",
    "        movies\n",
    ")\n",
    "\n",
    ", F AS (\n",
    "    SELECT\n",
    "        genre\n",
    "        , publish_year\n",
    "        , COUNT(DISTINCT movieId) AS movies\n",
    "    FROM\n",
    "        E\n",
    "    GROUP BY\n",
    "        1,2\n",
    "    ORDER BY\n",
    "        2,1\n",
    ")\n",
    "\n",
    "SELECT * FROM F\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "tView(sql, 'genres')\n",
    "sqlR(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b9cf5d",
   "metadata": {},
   "source": [
    "---\n",
    "## Load ☁️ ==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d252243",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table or view not found: genres;\n'UnresolvedRelation [genres], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m tempViews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mtable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m tempViews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mratings\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mtable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mratings\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m tempViews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenres\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m tempViews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenome_scores\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mtable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenome_scores\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m tempViews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenome_tags\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mtable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenome_tags\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pyspark/sql/session.py:1055\u001b[0m, in \u001b[0;36mSparkSession.table\u001b[0;34m(self, tableName)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtable\u001b[39m(\u001b[38;5;28mself\u001b[39m, tableName: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the specified table as a :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \n\u001b[1;32m   1042\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 2.0.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;124;03m    True\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1055\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtableName\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Table or view not found: genres;\n'UnresolvedRelation [genres], [], false\n"
     ]
    }
   ],
   "source": [
    "tempViews = {}\n",
    "\n",
    "tempViews['movies'] = spark.table('movies')\n",
    "tempViews['tags'] = spark.table('tags')\n",
    "tempViews['ratings'] = spark.table('ratings')\n",
    "tempViews['genres'] = spark.table('genres')\n",
    "tempViews['genome_scores'] = spark.table('genome_scores')\n",
    "tempViews['genome_tags'] = spark.table('genome_tags')\n",
    "\n",
    "for df in dfs:\n",
    "    print(df,'\\n |-->', dfs[df], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdd932e",
   "metadata": {},
   "source": [
    "---\n",
    "### Rascunho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a1be91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+------------+\n",
      "|movieId|title|genres|publish_year|\n",
      "+-------+-----+------+------------+\n",
      "+-------+-----+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "\n",
    "SELECT * FROM movies\n",
    "--WHERE title LIKE '%(500)%' OR title LIKE '%(69)%'\n",
    "--WHERE publish_year = ''\n",
    "--WHERE title LIKE '%Bicycle, Spoon, Apple%'\n",
    "--OR title LIKE '%Millions Game, The%'\n",
    "--WHERE publish_year IS NULL\n",
    "WHERE title IS NULL OR title = ''\n",
    "LIMIT 327\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "sqlR(sql)\n",
    "spark.sql(sql).show(truncate=False,n=327)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
